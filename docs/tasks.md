# LexPilot AI - Detaillierte Implementierungs-TODO-Liste

## üèóÔ∏è Phase 1: Projekt-Setup und Infrastruktur

### 1.1 Backend-Grundstruktur (Node.js + TypeScript + Firebase Functions)
```bash
# Projektstruktur mit Design Patterns
backend/
‚îú‚îÄ‚îÄ functions/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/              # Konfigurationsdateien
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ controllers/         # Request Handler (MVC Pattern)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/            # Business Logic (Service Layer Pattern)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repositories/        # Data Access Layer (Repository Pattern)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ factories/           # Factory Pattern Implementierungen
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ strategies/          # Strategy Pattern f√ºr Analysen
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ observers/           # Observer Pattern f√ºr Events
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ decorators/          # Decorator Pattern f√ºr Middleware
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/              # TypeScript Interfaces & Types
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ middleware/          # Express Middleware
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils/               # Helper Functions (Singleton Pattern f√ºr Logger)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chains/              # LangChain Implementierungen
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agents/              # LangChain Agents
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vectorstore/         # Pinecone Integration (Adapter Pattern)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ websocket/           # WebSocket Handler
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.ts             # Firebase Functions Entry Point
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ app.ts               # Express App Setup
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îú‚îÄ‚îÄ tsconfig.json
‚îÇ   ‚îî‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ firestore.rules              # Firestore Security Rules
‚îú‚îÄ‚îÄ storage.rules                # Storage Security Rules
‚îî‚îÄ‚îÄ firebase.json                # Firebase Configuration
```

**TODO:**
- [x] Firebase Functions mit TypeScript initialisieren
- [x] Express.js in Firebase Functions integrieren
- [x] Dependency Injection Container (Singleton Pattern f√ºr Logger)
- [x] Logger Service als Singleton implementieren:
  ```typescript
  class Logger {
    private static instance: Logger;
    private winston: Winston.Logger;
    
    constructor() {
      this.winston = winston.createLogger({...});
    }
    
    static getInstance(): Logger {
      if (!Logger.instance) {
        Logger.instance = new Logger();
      }
      return Logger.instance;
    }
  }
  ```
- [x] Error Handling mit Chain of Responsibility Pattern
- [x] Environment-basierte Konfiguration f√ºr Firebase Functions

## ‚úÖ Schritt 1.1 ABGESCHLOSSEN!

Das Backend-Setup ist erfolgreich implementiert mit:
- ‚úÖ Vollst√§ndige Projektstruktur mit Design Patterns
- ‚úÖ Firebase Functions mit TypeScript (Node.js 18)
- ‚úÖ Express.js App mit Security Middleware
- ‚úÖ Singleton Logger mit Winston
- ‚úÖ Chain of Responsibility Error Handling
- ‚úÖ Dependency Injection vorbereitet
- ‚úÖ Firestore & Storage Security Rules
- ‚úÖ Environment-Konfiguration mit Zod-Validation
- ‚úÖ Regionales Deployment (europe-west6)
- ‚úÖ Alle Dependencies installiert und Build erfolgreich

### 1.1 Frontend-Grundstruktur (Next.js 14)
Projektstruktur

frontend/src/
‚îú‚îÄ‚îÄ app/                # App Router
‚îÇ   ‚îú‚îÄ‚îÄ (auth)/         # Auth-gesch√ºtzte Routes
‚îÇ   ‚îú‚îÄ‚îÄ (public)/       # √ñffentliche Routes
‚îÇ   ‚îî‚îÄ‚îÄ api/            # API Routes
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ ui/             # Shadcn UI Components
‚îÇ   ‚îú‚îÄ‚îÄ features/       # Feature-spezifische Components
‚îÇ   ‚îî‚îÄ‚îÄ layouts/        # Layout Components
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îú‚îÄ‚îÄ hooks/          # Custom React Hooks
‚îÇ   ‚îú‚îÄ‚îÄ utils/          # Helper Functions
‚îÇ   ‚îî‚îÄ‚îÄ firebase/       # Firebase Client
‚îî‚îÄ‚îÄ types/              # TypeScript Types

TODO:

- [x] Next.js (neuste Version) mit App Router initialisieren
- [x] Tailwind CSS 4 konfigurieren
- [x] Theme anpassen (Darkmode hinzuf√ºgen)
- [x] TypeScript Strict Mode aktivieren
- [x] Zustand f√ºr State Management
- [x] React Query f√ºr Server State Management
- [x] WebSocket Client Setup (socket.io-client)


## üîß Phase 2: Core RAG System Implementation mit LangChain ‚úÖ ABGESCHLOSSEN!

### 2.1 LangChain Embeddings & LLM Setup ‚úÖ
**IMPLEMENTIERT:**
- ‚úÖ **EmbeddingService mit Multi-Model Support**:
  - OpenAI text-embedding-3-small/large Support
  - Dokumenttyp-basierte Model-Auswahl
  - Batch-Verarbeitung f√ºr Kostenoptimierung
  - Hierarchische Embedding-Strategien
  
- ‚úÖ **LLM Factory mit spezialisierten Models**:
  - Analysis LLM (Temperatur 0.1, JSON Output)
  - Generation LLM (Temperatur 0.3, Streaming)
  - Research LLM (Temperatur 0.2, gro√üe Token-Limits)
  - Validation LLM (Temperatur 0.0, maximale Konsistenz)
  - Summarization LLM (pr√§gnante Ausgaben)
  - Token-Kosten-Sch√§tzung implementiert

### 2.2 Text Splitting Strategies ‚úÖ
**IMPLEMENTIERT:**
- ‚úÖ **Hierarchischer Legal Document Splitter**:
  - 5 Chunk-Level: Chapter, Section, Clause, Table, Paragraph
  - Sprach-spezifische Separatoren (DE/FR/IT/EN)
  - Token-basierte Aufteilung f√ºr GPT-4 Kompatibilit√§t
  - Metadaten-Anreicherung mit Rechtsreferenzen
  - Automatische Struktur-Erkennung
  - Spezielle Tabellen-Behandlung

### 2.3 Advanced Chain Implementations ‚úÖ
**IMPLEMENTIERT:**
- ‚úÖ **Contract Analysis Chain mit IRAC Methodology**:
  - Issue Identification (strukturierte Rechtsfragen)
  - Rule Application (Schweizer Gesetze)
  - Application to Facts (Subsumtion)
  - Conclusion & Recommendations
  - Fortschritts-Updates via Observer Pattern
  - Comprehensive Validation mit Zod Schemas

- ‚úÖ **GDPR Compliance Chain mit Multi-Stage Validation**:
  - Datenminimierung nach DSGVO Art. 5 + DSG
  - Rechtsgrundlagen-Pr√ºfung
  - Einwilligungsmechanismen
  - Betroffenenrechte-Implementation
  - Automatische Risk-Level Bewertung
  - Prioritisierte Handlungsempfehlungen

### 2.4 Multi-Agent System Implementation ‚è≥ TEILWEISE
**IMPLEMENTIERT:**
- ‚úÖ **Base Classes f√ºr Agent-System**:
  - BaseObserver mit Observer Pattern
  - BaseLegalChain f√ºr alle Analysen
  - Error Handling und Logging

**TODO:**
- [ ] **LangGraph Integration f√ºr komplexe Workflows**
- [ ] **Hierarchical Agent System**
- [ ] **Specialized Agents** (Router, Extractor, Researcher, Analyzer)

### 2.5 Retrieval Optimization ‚úÖ
**IMPLEMENTIERT:**
- ‚úÖ **Hybrid Retrieval System**:
  - Semantic Search (Vector Store Mock)
  - Keyword Search (BM25 Mock)
  - Reciprocal Rank Fusion (60% semantic, 40% keyword)
  - Optional Cross-Encoder Re-ranking
  - Diversity Filtering f√ºr Ergebnis-Vielfalt
  - User-spezifische Namespaces
  - Performance Monitoring

## ‚úÖ TASK 2 ERFOLGREICH ABGESCHLOSSEN!

**Implementierte Komponenten:**
- ‚úÖ EmbeddingService mit Batch-Verarbeitung
- ‚úÖ LLMFactory mit 5 spezialisierten Models
- ‚úÖ LegalDocumentSplitter mit 5 Chunk-Levels
- ‚úÖ ContractAnalysisChain (IRAC Methodology)
- ‚úÖ GDPRComplianceChain (4 Compliance Checks)
- ‚úÖ HybridRetriever (Semantic + Keyword + Reranking)
- ‚úÖ Comprehensive Logging und Error Handling
- ‚úÖ Schweizer Recht-spezifische Implementierungen

**Features:**
- üöÄ Optimiert f√ºr Firebase Functions Deployment
- üí∞ Kosten-bewusste Batch-Verarbeitung
- üá®üá≠ Schweizer Rechts-spezifische Prompts und Separatoren
- üìä Strukturierte JSON-Ausgaben mit Zod Validation
- ‚ö° Performance-optimiert mit Caching
- üîí Type-safe TypeScript Implementation

**N√§chste Schritte:**
- Deployment und Integration mit Firebase Functions
- Frontend-Integration f√ºr Real-time Updates
- Vector Store Integration (Pinecone)
- Erweiterte Agent-Orchestrierung mit LangGraph

## üöÄ Phase 3: Firebase Functions Deployment

### 3.1 Firebase Functions Struktur
**TODO:**
- [ ] **Function Kategorien organisieren**:
  ```typescript
  // functions/src/index.ts
  import * as admin from 'firebase-admin';
  admin.initializeApp();
  
  // HTTP Functions
  export { api } from './http/api';
  export { webhooks } from './http/webhooks';
  
  // Scheduled Functions  
  export { dailyMaintenance } from './scheduled/maintenance';
  export { legalUpdates } from './scheduled/legalUpdates';
  
  // Firestore Triggers
  export { onDocumentCreated } from './triggers/document';
  export { onAnalysisCompleted } from './triggers/analysis';
  
  // Storage Triggers
  export { processUpload } from './triggers/storage';
  
  // Callable Functions
  export { analyzeDocument } from './callable/analyzeDocument';
  export { generateContract } from './callable/generateContract';
  ```

- [ ] **Memory und Timeout Optimierung**:
  ```typescript
  // F√ºr rechenintensive Operationen
  export const analyzeDocument = functions
    .region('europe-west6')
    .runWith({
      memory: '2GB',
      timeoutSeconds: 540, // 9 Minuten
      maxInstances: 10,
      minInstances: 0
    })
    .https.onCall(async (data, context) => {
      // Authentifizierung pr√ºfen
      if (!context.auth) {
        throw new functions.https.HttpsError(
          'unauthenticated',
          'User must be authenticated'
        );
      }
      
      // Rate Limiting per User
      await rateLimiter.checkLimit(context.auth.uid);
      
      // Document Analysis
      return await documentAnalysisService.analyze(data, context.auth.uid);
    });
  ```

### 3.2 Kosten-Optimierung f√ºr Firebase Functions
**TODO:**
- [ ] **Cold Start Minimierung**:
  ```typescript
  // Globale Variablen f√ºr Wiederverwendung
  let pineconeClient: PineconeClient | null = null;
  let openaiClient: OpenAI | null = null;
  
  function getPineconeClient(): PineconeClient {
    if (!pineconeClient) {
      pineconeClient = new PineconeClient();
      pineconeClient.init({
        apiKey: process.env.PINECONE_API_KEY!,
        environment: 'gcp-starter'
      });
    }
    return pineconeClient;
  }
  
  // Lazy Loading f√ºr schwere Dependencies
  const getLangChain = async () => {
    const { ChatOpenAI } = await import('langchain/chat_models/openai');
    return { ChatOpenAI };
  };
  ```

- [ ] **Batching f√ºr Embeddings**:
  ```typescript
  class EmbeddingBatcher {
    private queue: Array<{
      text: string;
      resolve: (embedding: number[]) => void;
      reject: (error: Error) => void;
    }> = [];
    
    private batchTimeout: NodeJS.Timeout | null = null;
    private readonly batchSize = 100; // OpenAI max batch size
    private readonly batchDelay = 100; // ms
    
    async getEmbedding(text: string): Promise<number[]> {
      return new Promise((resolve, reject) => {
        this.queue.push({ text, resolve, reject });
        
        if (this.queue.length >= this.batchSize) {
          this.processBatch();
        } else if (!this.batchTimeout) {
          this.batchTimeout = setTimeout(() => this.processBatch(), this.batchDelay);
        }
      });
    }
    
    private async processBatch() {
      if (this.batchTimeout) {
        clearTimeout(this.batchTimeout);
        this.batchTimeout = null;
      }
      
      const batch = this.queue.splice(0, this.batchSize);
      if (batch.length === 0) return;
      
      try {
        const embeddings = await openai.embeddings.create({
          model: process.env.OPENAI_API_EMBEDDINGS_MODELL,
          input: batch.map(item => item.text)
        });
        
        batch.forEach((item, index) => {
          item.resolve(embeddings.data[index].embedding);
        });
      } catch (error) {
        batch.forEach(item => item.reject(error as Error));
      }
    }
  }
  ```

## üìä Phase 4: Monitoring & Analytics

### 4.1 Custom Analytics mit Firebase
**TODO:**
- [ ] **Usage Tracking Service**:
  ```typescript
  class AnalyticsService {
    async trackUsage(userId: string, action: UsageAction, metadata: any) {
      // Firebase Analytics f√ºr aggregierte Metriken
      await analytics.logEvent(action, {
        user_id: userId,
        ...metadata
      });
      
      // Firestore f√ºr detaillierte Auswertungen
      await firestore.collection('usage').add({
        userId,
        action,
        metadata,
        timestamp: FieldValue.serverTimestamp(),
        cost: this.calculateCost(action, metadata)
      });
      
      // Update User Quotas
      await this.updateUserQuota(userId, action);
    }
    
    private calculateCost(action: UsageAction, metadata: any): number {
      const costs = {
        embedding: 0.0001 * (metadata.tokens / 1000),
        gpt4Analysis: 0.03 * (metadata.inputTokens / 1000) + 0.06 * (metadata.outputTokens / 1000),
        gpt35Generation: 0.001 * (metadata.inputTokens / 1000) + 0.002 * (metadata.outputTokens / 1000),
        storage: 0.02 * (metadata.sizeInMB / 1000), // per GB
        vectorStorage: 0.00001 * metadata.vectorCount
      };
      
      return costs[action] || 0;
    }
  }
  ```

- [ ] **Dashboard Metriken Aggregation**:
  ```typescript
  export const updateDashboardMetrics = functions
    .region('europe-west6')
    .pubsub.schedule('every 5 minutes')
    .onRun(async (context) => {
      const metrics = await aggregateMetrics();
      
      // Cache in Firestore f√ºr schnellen Zugriff
      await firestore
        .collection('dashboards')
        .doc('global')
        .set({
          activeContracts: metrics.activeContracts,
          highRiskItems: metrics.highRiskItems,
          upcomingDeadlines: metrics.upcomingDeadlines,
          monthlyVolume: metrics.monthlyVolume,
          lastUpdated: FieldValue.serverTimestamp()
        });
    });
  ```

Diese erweiterte TODO-Liste bietet dir nun:

1. **Firebase Functions** als Hosting-L√∂sung mit detaillierter Konfiguration
2. **Design Patterns** durchg√§ngig integriert in die Architektur
3. **Umfassende .gitignore** Konfiguration
4. **Detaillierte LangChain Implementation** mit:
   - Spezifischen Embedding-Modellen (Multilingual E5, Legal-BERT)
   - LLM-Auswahl (GPT-4.1)
   - Hierarchische TextSplitter f√ºr Rechtstexte
   - Multi-Agent System mit LangGraph
   - Hybrid Retrieval mit BM25 und Semantic Search

Die Implementierung nutzt Firebase Functions optimal f√ºr:
- Kosten-Minimierung durch Cold Start Optimierung
- Skalierbarkeit durch automatisches Scaling
- Integration mit Firebase Services (Auth, Firestore, Storage)
- Regionale Deployment in Europa (Z√ºrich)


üî• Firebase Functions als Backend-Hosting

Regionales Deployment in europe-west6 (Z√ºrich)
Optimierte Memory/Timeout Konfigurationen
Cold Start Minimierung durch globale Variablen
Kosten-effiziente Batch-Verarbeitung

üèóÔ∏è Design Patterns durchg√§ngig integriert

Repository Pattern f√ºr Data Access Layer
Factory Pattern f√ºr Chain/Agent-Erstellung
Strategy Pattern f√ºr verschiedene Analyse-Typen
Observer Pattern f√ºr WebSocket Updates
Singleton Pattern f√ºr Logger und Services

ü§ñ Detaillierte LangChain/RAG Implementation
Embedding-Modelle:

OpenAI process.env.OPENAI_API_EMBEDDINGS_MODELL - Kosten-effizient als Fallback

LLM-Strategie:

GPT-4.1 Turbo - F√ºr kritische Analysen (Temperatur 0.1)

Text-Splitting:

Hierarchisch mit 3 Ebenen (Kapitel ‚Üí Sections ‚Üí Klauseln)
Sprach-spezifische Separatoren f√ºr DE/FR/IT/EN
Token-basiert f√ºr pr√§zise GPT-4 Kompatibilit√§t

üí° Praktische Implementierungs-Tipps
Starte mit diesem MVP-Ansatz:

Woche 1: Firebase Setup + Basic Express API
Woche 2: Pinecone Integration + Document Upload
Woche 3: Erste LangChain DSGVO-Check Chain
Woche 4: WebSocket f√ºr Real-time Updates

Kosten-Kontrolle von Anfang an:
typescript// Implementiere Token-Tracking
class TokenTracker {
  async trackTokens(userId: string, tokens: number, model: string) {
    const cost = this.calculateCost(tokens, model);
    await this.updateUserUsage(userId, cost);
    
    // Warnung bei 80% Budget-Auslastung
    if (await this.isNearingLimit(userId)) {
      await this.sendBudgetWarning(userId);
    }
  }
}
Schweiz-spezifische Features:

Implementiere mehrsprachige Prompts (DE/FR/IT) von Beginn an
Nutze Schweizer Rechtsquellen f√ºr Retrieval (admin.ch, etc.)
Beachte kantonale Unterschiede bei der Analyse

Performance-Optimierung:

Cache alle Embeddings in Firestore (24h TTL)
Nutze Streaming f√ºr lange Analysen
Implementiere Progressive Enhancement im Frontend